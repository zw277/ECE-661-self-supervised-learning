{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29277,"status":"ok","timestamp":1702264974270,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"K-YUWpJwNrio","outputId":"1957e9d0-57c1-427e-9a3f-102512598e5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/final_project')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5568,"status":"ok","timestamp":1702264979998,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"MVxAxTFAjU_A","outputId":"2b9f4f5e-6d94-46d8-ed59-55e2c78309b1"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.models import resnet50\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.models as models\n","import matplotlib.pyplot as plt\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n","device"]},{"cell_type":"markdown","metadata":{"id":"AgsYOAsD8JfD"},"source":["## method 2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1702264979998,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"ytJ2N4MLb9he"},"outputs":[],"source":["class ResNet50(nn.Module):\n","    def __init__(self, projection_dim=128):\n","        super(ResNet50, self).__init__()\n","        self.resnet50 = models.resnet50(pretrained=False)\n","        self.resnet50.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.resnet50.maxpool = nn.Identity()\n","        feature_dim = self.resnet50.fc.in_features\n","        self.resnet50.fc = nn.Sequential(\n","            nn.Linear(feature_dim, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, projection_dim)\n","        )\n","\n","    def forward(self, x):\n","        projection = self.resnet50(x)\n","        return projection"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1702264980158,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"pPEi9Ceo-zdd"},"outputs":[],"source":["def color_distortion(s=0.5):\n","    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n","    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n","    rnd_gray = transforms.RandomGrayscale(p=0.2)\n","    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n","    return color_distort\n","\n","# Set the strength of color distortion\n","s = 0.5\n","\n","# train dataset\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(32),\n","    transforms.RandomHorizontalFlip(),\n","    color_distortion(s),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n","])\n","# test_transform = transforms.Compose([\n","#     transforms.ToTensor(),\n","#     transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n","# ])\n","test_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(32),\n","    transforms.RandomHorizontalFlip(),\n","    color_distortion(s),\n","    transforms.ToTensor(),\n","    # transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n","])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6966,"status":"ok","timestamp":1702264987122,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"IAStepps-F57","outputId":"70c3a1c9-d5b6-4dff-cfe8-0d04de17e599"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["from torchvision.datasets import CIFAR10\n","from PIL import Image\n","# from dataset import CIFAR10Pair, test_CIFAR10Pair\n","\n","class CIFAR10Pair(CIFAR10):\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","        # Apply transformations twice to get a pair of different augmentations\n","        img1 = train_transform(img)\n","        img2 = train_transform(img)\n","        return img1, img2, target\n","\n","class test_CIFAR10Pair(CIFAR10):\n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","        # Apply transformations twice to get a pair of different augmentations\n","        img1 = test_transform(img)\n","        img2 = test_transform(img)\n","        return img1, img2, target\n","\n","# Initialize the CIFAR-10 Pair dataset\n","train_dataset = CIFAR10Pair(root='./cifar10', train=True, download=True)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n","\n","# # Initialize the CIFAR-10 Pair dataset\n","test_dataset = test_CIFAR10Pair(root='./cifar10', train=False, download=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1702264987122,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"PpvzBFFecCl_"},"outputs":[],"source":["def nt_xent_loss(z_i, z_j, temperature):\n","    \"\"\"\n","    Compute the NT-Xent loss.\n","\n","    Arguments:\n","    z_i, z_j -- Representations of positive pairs. Each should be of shape (batch_size, feature_size).\n","    temperature -- A temperature scaling parameter.\n","\n","    Returns:\n","    Loss computed from the batch of representations.\n","    \"\"\"\n","    N, Z = z_i.shape  # Batch size and feature dimension\n","\n","    # Normalize the representations\n","    z_i = F.normalize(z_i, p=2, dim=1)\n","    z_j = F.normalize(z_j, p=2, dim=1)\n","\n","    # Concatenate the representations\n","    representations = torch.cat([z_i, z_j], dim=0)\n","\n","    # Compute cosine similarity\n","    similarity_matrix = torch.matmul(representations, representations.T)\n","\n","    # Create the mask for positive samples\n","    l_pos = torch.diag(similarity_matrix, N)\n","    r_pos = torch.diag(similarity_matrix, -N)\n","    positives = torch.cat([l_pos, r_pos]).view(2 * N, 1)\n","\n","    # Mask for removing the similarity of each element with itself\n","    diag_mask = ~(torch.eye(2 * N).bool())\n","\n","    # Extract the negatives\n","    negatives = similarity_matrix[diag_mask].view(2 * N, -1)\n","\n","    # Combine positives with negatives\n","    logits = torch.cat([positives, negatives], dim=1)\n","\n","    # Apply temperature scaling\n","    logits /= temperature\n","\n","    # Labels: positives are the first elements\n","    labels = torch.zeros(2 * N).to(z_i.device).long()\n","\n","    # Calculate the cross-entropy loss\n","    loss = F.cross_entropy(logits, labels)\n","\n","    return loss\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1702264987123,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"utLNoTS-Gm6Q"},"outputs":[],"source":["def contrastive_accuracy(z_i, z_j, labels):\n","    with torch.no_grad():\n","        # Compute the cosine similarity\n","        similarity_matrix = F.cosine_similarity(z_i.unsqueeze(1), z_j.unsqueeze(0), dim=2)\n","\n","        # Get the indices of the maximum values along each row\n","        max_indices = similarity_matrix.max(dim=1)[1]\n","\n","        # Calculate accuracy\n","        correct = (labels == labels[max_indices]).float()\n","        return correct.mean()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145061,"status":"ok","timestamp":1702270734936,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"DfZjqFVIGq4Y","outputId":"b0e617a5-dc05-4f8a-a4ae-912a7b009e03"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [185/200], Batch [200/781], Train Loss: 3.3530, Train Accuracy: 0.9375\n","Epoch [185/200], Batch [400/781], Train Loss: 3.3287, Train Accuracy: 0.9219\n","Epoch [185/200], Batch [600/781], Train Loss: 3.3439, Train Accuracy: 0.9062\n","Epoch [185/200], Train Loss: 3.3391, Train Accuracy: 0.9021, Test Loss: 3.3754, Test Accuracy: 0.8959\n","Saved best model at epoch 185, with test loss: 3.3754, test accuracy: 0.8959\n","Epoch [186/200], Batch [200/781], Train Loss: 3.3715, Train Accuracy: 0.8594\n","Epoch [186/200], Batch [400/781], Train Loss: 3.3926, Train Accuracy: 0.8750\n","Epoch [186/200], Batch [600/781], Train Loss: 3.2461, Train Accuracy: 0.9531\n","Epoch [186/200], Train Loss: 3.3398, Train Accuracy: 0.9004, Test Loss: 3.3741, Test Accuracy: 0.8872\n","Saved best model at epoch 186, with test loss: 3.3741, test accuracy: 0.8872\n","Epoch [187/200], Batch [200/781], Train Loss: 3.2846, Train Accuracy: 0.9531\n","Epoch [187/200], Batch [400/781], Train Loss: 3.3157, Train Accuracy: 0.8906\n","Epoch [187/200], Batch [600/781], Train Loss: 3.2961, Train Accuracy: 0.9688\n","Epoch [187/200], Train Loss: 3.3383, Train Accuracy: 0.9027, Test Loss: 3.3783, Test Accuracy: 0.8903\n","Epoch [188/200], Batch [200/781], Train Loss: 3.3649, Train Accuracy: 0.8750\n","Epoch [188/200], Batch [400/781], Train Loss: 3.3580, Train Accuracy: 0.8906\n","Epoch [188/200], Batch [600/781], Train Loss: 3.2606, Train Accuracy: 0.9219\n","Epoch [188/200], Train Loss: 3.3373, Train Accuracy: 0.9043, Test Loss: 3.3746, Test Accuracy: 0.8953\n","Epoch [189/200], Batch [200/781], Train Loss: 3.3777, Train Accuracy: 0.8438\n","Epoch [189/200], Batch [400/781], Train Loss: 3.3532, Train Accuracy: 0.9219\n","Epoch [189/200], Batch [600/781], Train Loss: 3.4314, Train Accuracy: 0.8750\n","Epoch [189/200], Train Loss: 3.3396, Train Accuracy: 0.9014, Test Loss: 3.3809, Test Accuracy: 0.8929\n","Epoch [190/200], Batch [200/781], Train Loss: 3.3425, Train Accuracy: 0.9219\n","Epoch [190/200], Batch [400/781], Train Loss: 3.3539, Train Accuracy: 0.8906\n","Epoch [190/200], Batch [600/781], Train Loss: 3.3263, Train Accuracy: 0.9062\n","Epoch [190/200], Train Loss: 3.3364, Train Accuracy: 0.9017, Test Loss: 3.3774, Test Accuracy: 0.8938\n","Epoch [191/200], Batch [200/781], Train Loss: 3.3425, Train Accuracy: 0.8906\n","Epoch [191/200], Batch [400/781], Train Loss: 3.3074, Train Accuracy: 0.9219\n","Epoch [191/200], Batch [600/781], Train Loss: 3.3273, Train Accuracy: 0.9375\n","Epoch [191/200], Train Loss: 3.3372, Train Accuracy: 0.9024, Test Loss: 3.3759, Test Accuracy: 0.8875\n","Epoch [192/200], Batch [200/781], Train Loss: 3.3532, Train Accuracy: 0.8750\n","Epoch [192/200], Batch [400/781], Train Loss: 3.3058, Train Accuracy: 0.8594\n","Epoch [192/200], Batch [600/781], Train Loss: 3.3304, Train Accuracy: 0.9062\n","Epoch [192/200], Train Loss: 3.3359, Train Accuracy: 0.9034, Test Loss: 3.3745, Test Accuracy: 0.8905\n","Epoch [193/200], Batch [200/781], Train Loss: 3.4811, Train Accuracy: 0.7969\n","Epoch [193/200], Batch [400/781], Train Loss: 3.3607, Train Accuracy: 0.8594\n","Epoch [193/200], Batch [600/781], Train Loss: 3.2996, Train Accuracy: 0.9062\n","Epoch [193/200], Train Loss: 3.3353, Train Accuracy: 0.9017, Test Loss: 3.3767, Test Accuracy: 0.8955\n","Epoch [194/200], Batch [200/781], Train Loss: 3.3237, Train Accuracy: 0.9375\n","Epoch [194/200], Batch [400/781], Train Loss: 3.3390, Train Accuracy: 0.8438\n","Epoch [194/200], Batch [600/781], Train Loss: 3.2762, Train Accuracy: 0.9531\n","Epoch [194/200], Train Loss: 3.3373, Train Accuracy: 0.9017, Test Loss: 3.3721, Test Accuracy: 0.8889\n","Saved best model at epoch 194, with test loss: 3.3721, test accuracy: 0.8889\n","Epoch [195/200], Batch [200/781], Train Loss: 3.3356, Train Accuracy: 0.9531\n","Epoch [195/200], Batch [400/781], Train Loss: 3.3305, Train Accuracy: 0.9219\n","Epoch [195/200], Batch [600/781], Train Loss: 3.3186, Train Accuracy: 0.9375\n","Epoch [195/200], Train Loss: 3.3354, Train Accuracy: 0.9042, Test Loss: 3.3702, Test Accuracy: 0.8962\n","Saved best model at epoch 195, with test loss: 3.3702, test accuracy: 0.8962\n","Epoch [196/200], Batch [200/781], Train Loss: 3.3580, Train Accuracy: 0.8594\n","Epoch [196/200], Batch [400/781], Train Loss: 3.3080, Train Accuracy: 0.9219\n","Epoch [196/200], Batch [600/781], Train Loss: 3.3360, Train Accuracy: 0.9062\n","Epoch [196/200], Train Loss: 3.3371, Train Accuracy: 0.9034, Test Loss: 3.3684, Test Accuracy: 0.8923\n","Saved best model at epoch 196, with test loss: 3.3684, test accuracy: 0.8923\n","Epoch [197/200], Batch [200/781], Train Loss: 3.2997, Train Accuracy: 0.9688\n","Epoch [197/200], Batch [400/781], Train Loss: 3.3232, Train Accuracy: 0.8906\n","Epoch [197/200], Batch [600/781], Train Loss: 3.3339, Train Accuracy: 0.9219\n","Epoch [197/200], Train Loss: 3.3366, Train Accuracy: 0.9037, Test Loss: 3.3678, Test Accuracy: 0.8993\n","Saved best model at epoch 197, with test loss: 3.3678, test accuracy: 0.8993\n","Epoch [198/200], Batch [200/781], Train Loss: 3.3780, Train Accuracy: 0.8594\n","Epoch [198/200], Batch [400/781], Train Loss: 3.2587, Train Accuracy: 0.9531\n","Epoch [198/200], Batch [600/781], Train Loss: 3.3700, Train Accuracy: 0.8906\n","Epoch [198/200], Train Loss: 3.3347, Train Accuracy: 0.9044, Test Loss: 3.3830, Test Accuracy: 0.8850\n","Epoch [199/200], Batch [200/781], Train Loss: 3.3029, Train Accuracy: 0.9375\n","Epoch [199/200], Batch [400/781], Train Loss: 3.2846, Train Accuracy: 0.9375\n","Epoch [199/200], Batch [600/781], Train Loss: 3.3445, Train Accuracy: 0.8281\n","Epoch [199/200], Train Loss: 3.3330, Train Accuracy: 0.9024, Test Loss: 3.3692, Test Accuracy: 0.9008\n","Epoch [200/200], Batch [200/781], Train Loss: 3.3235, Train Accuracy: 0.9219\n","Epoch [200/200], Batch [400/781], Train Loss: 3.3574, Train Accuracy: 0.9062\n","Epoch [200/200], Batch [600/781], Train Loss: 3.4008, Train Accuracy: 0.9062\n","Epoch [200/200], Train Loss: 3.3366, Train Accuracy: 0.9027, Test Loss: 3.3666, Test Accuracy: 0.8970\n","Saved best model at epoch 200, with test loss: 3.3666, test accuracy: 0.8970\n","Epoch [201/200], Batch [200/781], Train Loss: 3.3141, Train Accuracy: 0.8906\n","Epoch [201/200], Batch [400/781], Train Loss: 3.3369, Train Accuracy: 0.9062\n","Epoch [201/200], Batch [600/781], Train Loss: 3.3255, Train Accuracy: 0.8750\n","Epoch [201/200], Train Loss: 3.3329, Train Accuracy: 0.9039, Test Loss: 3.3716, Test Accuracy: 0.8945\n","Training Completed\n"]}],"source":["model = ResNet50().to(device)\n","\n","# Load the saved model state\n","model.load_state_dict(torch.load('simclr_resnet50_64_108to200ep.pt'))\n","\n","# Optimizer setup\n","optimizer = optim.Adam(model.parameters(), lr=0.5)\n","\n","# Number of additional epochs to train\n","num_epochs = 200\n","additional_epochs = 16\n","start_epoch = 185\n","end_epoch = start_epoch + additional_epochs\n","\n","best_val_loss = float('inf')\n","\n","train_loss_list = []\n","train_accuracy_list = []\n","test_loss_list = []\n","test_accuracy_list = []\n","\n","\n","# Training loop\n","for epoch in range(start_epoch, end_epoch + 1):\n","    model.train()\n","    total_loss = 0\n","    total_accuracy = 0\n","\n","    for batch_idx, (img1, img2, labels) in enumerate(train_loader):\n","        img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","        # Forward pass\n","        z_i = model(img1)\n","        z_j = model(img2)\n","\n","        # Compute NT-Xent Loss\n","        loss = nt_xent_loss(z_i, z_j, temperature=0.5)\n","\n","        # Compute accuracy\n","        # train_accuracy = contrastive_accuracy(z_i, z_j)\n","        train_accuracy = contrastive_accuracy(z_i, z_j, labels)\n","        total_accuracy += train_accuracy.item()\n","\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","        # Print loss and accuracy every 10 batches\n","        if (batch_idx + 1) % 200 == 0:\n","            print(f'Epoch [{epoch}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.4f}')\n","\n","    # Average loss and accuracy for this epoch\n","    avg_loss = total_loss / len(train_loader)\n","    avg_accuracy = total_accuracy / len(train_loader)\n","\n","    # Evaluate on test set\n","    model.eval()\n","    total_test_loss = 0\n","    total_test_accuracy = 0\n","    with torch.no_grad():\n","        for batch_idx, (img1, img2, labels) in enumerate(test_loader):\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","            z_i = model(img1)\n","            z_j = model(img2)\n","            # Assuming you have a way to calculate test loss, e.g., CrossEntropyLoss for classification\n","            test_loss = nt_xent_loss(z_i, z_j, temperature=0.5)\n","            total_test_loss += test_loss.item()\n","            # Compute accuracy\n","            # test_accuracy = contrastive_accuracy(z_i, z_j)\n","            test_accuracy = contrastive_accuracy(z_i, z_j, labels)\n","\n","            total_test_accuracy += test_accuracy.item()\n","            avg_test_loss = total_test_loss / len(test_loader)\n","            avg_test_accuracy = total_test_accuracy / len(test_loader)\n","    # test_loss, test_accuracy = evaluate_on_test(model, test_loader, device)\n","    print(f'Epoch [{epoch}/{num_epochs}], Train Loss: {avg_loss:.4f}, Train Accuracy: {avg_accuracy:.4f}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_accuracy:.4f}')\n","    train_loss_list.append(avg_loss)\n","    train_accuracy_list.append(avg_accuracy)\n","    test_loss_list.append(avg_test_loss)\n","    test_accuracy_list.append(avg_test_accuracy)\n","\n","    # Save model if it has best test loss yet\n","    if avg_test_loss < best_val_loss:\n","        best_val_loss = avg_test_loss\n","        torch.save(model.state_dict(), f'simclr_resnet50_64_185to200ep.pt')\n","        print(f\"Saved best model at epoch {epoch}, with test loss: {best_val_loss:.4f}, test accuracy: {avg_test_accuracy:.4f}\")\n","\n","print(\"Training Completed\")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1702270736236,"user":{"displayName":"yuner","userId":"17042565881765632376"},"user_tz":300},"id":"fpnC94L4_uZD","outputId":"362ee470-e204-4da6-bfa0-56954f0d0fab"},"outputs":[{"data":{"text/plain":["0.9008413461538461"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["max(test_accuracy_list)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"1839519941b59dcc99fafb6893b85c8db0c33337004191e59958f8918fcc434b"}}},"nbformat":4,"nbformat_minor":0}
